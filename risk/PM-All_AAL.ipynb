{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AAL Master Papermill\n",
    "Use papermill to create all notebooks and outputs of the AAL calculator\n",
    "## Workflow:\n",
    "1. **Run notebook:** `Prep_AAL_Inputs.ipynb`\n",
    "2. **Run notebook:** `AAL-Calculator.ipynb`\n",
    "3. **Run notebook:** `CreateAALResults.ipynb`\n",
    "4. **Run notebook:** `AAL-ResultSummary.ipynb`\n",
    "5. **Run notebook:** `AAL-AnomalyReport.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import papermill as pm\n",
    "from glob import glob\n",
    "import pathlib as pl\n",
    "import sys; sys.path.append('../core')\n",
    "from risk_refactor import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'DC'\n",
    "models = ['F02']\n",
    "books = ['MB', 'Uncorrelated', 'Uniform']\n",
    "tri = ''  # if IT IS NOT a TRI run\n",
    "# tri = '_TRI'  # if IT IS a TRI run\n",
    "output_dir_name = 'outputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manage and organize file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = join(os.getcwd(), output_dir_name, project + tri)\n",
    "dir_json = setup_file_structure(output_dir, models)\n",
    "notebook_dir = join(output_dir, 'notebooks')\n",
    "if not exists(notebook_dir): os.makedirs(notebook_dir)\n",
    "print('Output location:', output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run notebook:** `Prep_AAL_Inputs.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "\n",
    "for mod in models:\n",
    "    print(mod)\n",
    "    paramdict = {'project': project,\n",
    "                 'model': mod,\n",
    "                 'TRI': tri,\n",
    "                 'wse_dir': dir_json[mod][WSE],\n",
    "                 'weights_dir': dir_json[mod][WEIGHTS]}\n",
    "    pm.execute_notebook('Prep_AAL_inputs.ipynb', join(notebook_dir, '_'.join([project, mod, 'Prep_AAL_inputs.ipynb'])), parameters=paramdict, kernel_name='python3')\n",
    "    \n",
    "print(round((time()-st)/60, 2), 'minutes to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to s3\n",
    "for mod in models:\n",
    "    print(mod)\n",
    "    outwses = glob(join(dir_json[mod][WSE], '*.csv'))\n",
    "    outwts = glob(join(dir_json[mod][WEIGHTS], '*.csv'))\n",
    "    if tri:\n",
    "        for wse in outwses:\n",
    "            book = os.path.basename(wse).split('_')[-2]\n",
    "            os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/TRI/{2}/WSE_{1}_{2}_{3}_TRI.csv'.format(wse, project, mod, book))\n",
    "        for wt in outwts:\n",
    "            os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/TRI/{2}/{1}_{2}_weights_TRI.csv'.format(wt, project, mod))\n",
    "    else:\n",
    "        for wse in outwses:\n",
    "            book = os.path.basename(wse).split('_')[-1].split('.')[0]\n",
    "            os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/{2}/WSE_{1}_{2}_{3}.csv'.format(wse, project, mod, book))\n",
    "        for wt in outwts:\n",
    "            os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/{2}/{1}_{2}_weights.csv'.format(wt, project, mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run notebook:** `AAL-Calculator.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Hazus data:\n",
    "hzDDFnIdJson = r'hazusdepthdmgfns\\Building_DDF_Full_LUT_Hazus3p0.json'\n",
    "\n",
    "# Damage categories:\n",
    "catgroups = {'singFam_1Story_NoBasement' : [105, 129, 132, 139, 173],\n",
    "             'singFam_2Story_NoBasement' : [107, 130, 136, 140, 174],\n",
    "             'singFam_3Story_NoBasement' : [109],\n",
    "             'singFam_1Story_Basement' : [106, 121, 133, 181, 704],\n",
    "             'singFam_2Story_Basement' : [108, 122, 137],\n",
    "             'singFam_3Story_Basement' : [110, 123],\n",
    "             'mobileHome': [189, 191, 192, 203]}\n",
    "\n",
    "field_map = {'Unique Building ID' : 'plus_code',\n",
    "             'Damage Code': 'damage_code',\n",
    "             'Building Limit' : 'bldg_limit',\n",
    "             'Building Deduction' : 'bldg_ded',\n",
    "             'Content Limit' : 'cnt_limit',\n",
    "             'Content Deduction': 'cnt_ded',\n",
    "             'Ground Elevation': 'GroundElev',\n",
    "             'First Floor Height': 'first_floor_elev'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "\n",
    "root = pl.Path(os.getcwd())\n",
    "for mod in models:\n",
    "    for book in books:\n",
    "        print(mod, book)\n",
    "        wse_path = [x for x in glob(join(dir_json[mod][WSE], '*.csv')) if book in x][0]\n",
    "        if mod[0] == 'P':\n",
    "            weights_file = glob(join(dir_json[mod][WEIGHTS], '*.csv'))[0]\n",
    "        else:\n",
    "            weights_file = ''\n",
    "        \n",
    "        scenname = pl.Path(wse_path).stem.replace('WSE_', '')\n",
    "        paramdict = dict(root_dir = str(root),\n",
    "                         wse_file = wse_path,\n",
    "                         weights_path = weights_file,\n",
    "                         curve_groups = catgroups,\n",
    "                         structure_cols = field_map,\n",
    "                         out_AAL = join(dir_json[mod][AAL], 'AAL_{}.csv'.format(scenname)),\n",
    "                         out_loss = join(dir_json[mod][AAL], 'Losses_{}.csv'.format(scenname)),\n",
    "                         scen = scenname)\n",
    "    \n",
    "        print('Using weights file:', weights_file)\n",
    "        out_nb = join(dir_json[mod][AAL], 'tool_{}.ipynb'.format(scenname))\n",
    "        pm.execute_notebook('AAL-Calculator.ipynb', out_nb, parameters=paramdict, kernel_name='python3')\n",
    "        os.system('jupyter nbconvert {}'.format(out_nb))\n",
    "        \n",
    "print(round((time()-st)/60, 2), 'minutes to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to s3\n",
    "for mod in models:\n",
    "    print(mod)\n",
    "    outfiles = [x for x in glob(join(dir_json[mod][AAL], '*')) if not 'Losses' in x]\n",
    "    if tri:\n",
    "        for f in outfiles:\n",
    "            os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/{2}/{3}'.format(f, project, mod, os.path.basename(f).replace('_TRI', '')))\n",
    "    else:\n",
    "        for f in outfiles:\n",
    "            os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/{2}/{3}'.format(f, project, mod, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run notebook:** `CreateAALResults.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "\n",
    "for book in books:\n",
    "    paramdict = {'project': project,\n",
    "                 'book': book,\n",
    "                 'TRI': tri,\n",
    "                 'output_dir': dir_json[FAAL]}\n",
    "    \n",
    "    print('Working on {} for {}'.format(book, project))\n",
    "    pm.execute_notebook('CreateAALResults.ipynb', join(notebook_dir, '_'.join([project, book, 'CreateAALResults.ipynb'])), parameters=paramdict, kernel_name='python3')\n",
    "    \n",
    "print(round((time()-st)/60, 2), 'minutes to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to s3\n",
    "outfiles = glob(join(dir_json[FAAL], '*'))\n",
    "if tri:\n",
    "    for f in outfiles:\n",
    "        os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/TRI/AALs/{2}'.format(f, project, os.path.basename(f)))\n",
    "else:\n",
    "    for f in outfiles:\n",
    "        os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/AALs/{2}'.format(f, project, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run notebook:** `AAL-ResultSummary.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "\n",
    "for book in books:\n",
    "    paramdict = {'project': project,\n",
    "                 'book': book,\n",
    "                 'TRI': tri,\n",
    "                 'outlier_threshold': 3000}\n",
    "    \n",
    "    print('Working on {} for {}'.format(book, project))\n",
    "    out_nb = join(dir_json[SUM], '_'.join([project, book, 'AAL-ResultSummary.ipynb']))\n",
    "    pm.execute_notebook('AAL-ResultSummary.ipynb', out_nb, parameters=paramdict, kernel_name='python3')\n",
    "    os.system('jupyter nbconvert {}'.format(out_nb))\n",
    "    \n",
    "print(round((time()-st)/60, 2), 'minutes to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to s3\n",
    "outfiles = glob(join(dir_json[SUM], '*.html'))\n",
    "if tri:\n",
    "    for f in outfiles:\n",
    "        os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/TRI/AALs/{2}'.format(f, project, os.path.basename(f)))\n",
    "else:\n",
    "    for f in outfiles:\n",
    "        os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/AALs/{2}'.format(f, project, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Run notebook:** `AAL-AnomalyReport.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time()\n",
    "\n",
    "for book in books:\n",
    "    paramdict = {'project': project,\n",
    "                 'book': book,\n",
    "                 'TRI': tri,\n",
    "                 'anom_threshold': 3000}\n",
    "    \n",
    "    print('Working on {} for {}'.format(book, project))\n",
    "    out_nb = join(dir_json[ANOM], '_'.join([project, book, 'AAL-AnomalyReport.ipynb']))\n",
    "    pm.execute_notebook('AAL-AnomalyReport.ipynb', out_nb, parameters=paramdict, kernel_name='python3')\n",
    "    os.system('jupyter nbconvert {}'.format(out_nb))\n",
    "    \n",
    "print(round((time()-st)/60, 2), 'minutes to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to s3\n",
    "outfiles = glob(join(dir_json[ANOM], '*.html'))\n",
    "if tri:\n",
    "    for f in outfiles:\n",
    "        os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/TRI/AALs/{2}'.format(f, project, os.path.basename(f)))\n",
    "else:\n",
    "    for f in outfiles:\n",
    "        os.system('aws s3 cp {0} s3://pfra/RiskAssessment/{1}/Results/AALs/{2}'.format(f, project, os.path.basename(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
