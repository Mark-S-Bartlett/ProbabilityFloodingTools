{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Final AAL Results File\n",
    "This notebook reads the results of the AAL Calculator from s3 and joins them together to create a final AAL results csv file for an entire project area.\n",
    "\n",
    "In order for this notebook to be run successfully, all of the results of the AAL Calculator must be in the right location on s3.\n",
    "\n",
    "User inputs:\n",
    " - project (e.g. `'DC'`)\n",
    " - book (e.g. `'Uniform'`)\n",
    " \n",
    "Author: Alec Brazeau - abrazeau@dewberry.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys; sys.path.append('../core')\n",
    "from s3utils import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User specified parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRI:\n",
    "    aal_files = s3List('pfra', 'RiskAssessment/{}/Results/TRI'.format(project), 'AAL', '.csv')\n",
    "else:\n",
    "    aal_files = [x for x in s3List('pfra', 'RiskAssessment/{}/Results'.format(project), 'AAL', '.csv') if not 'TRI' in x]\n",
    "s3files = [x for x in aal_files if book in x and 'Final' not in x and 'Losses' not in x and 'anoms' not in x]\n",
    "s3files = [f for f in s3files if not '/A/' in f and not '/B/' in f]\n",
    "print('Files to be joined:')\n",
    "for x in s3files: print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_codes = []\n",
    "# read all points, make a set of unique plus codes from all\n",
    "# Make attribute tables from current csvs\n",
    "for f in s3files:\n",
    "    temp = pd.read_csv(f)\n",
    "    for idx in temp['plus_code']:\n",
    "        plus_codes.append(idx)\n",
    "        \n",
    "idx = list(set(plus_codes))\n",
    "print('Total points in {} {}: {}'.format(project, book, len(idx)))\n",
    "fluvial_joined = pd.DataFrame(index=idx)\n",
    "pluvial_joined = pd.DataFrame(index=idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Fluvial AAL Results First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through fluvials\n",
    "fluv_s3files = [x for x in s3files if 'F0' in x]\n",
    "for f in fluv_s3files:\n",
    "    if TRI:\n",
    "        model = os.path.basename(f).split('_')[-3]\n",
    "    else:\n",
    "        model = os.path.basename(f).split('_')[-2]\n",
    "    df = pd.read_csv(f)\n",
    "    df.rename(columns={'AAL':'{}_AAL'.format(model)}, inplace=True)\n",
    "    df.set_index('plus_code', inplace=True)\n",
    "    fluvial_joined = fluvial_joined.join(df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_joined['FLUV_AAL'] = fluvial_joined.sum(axis=1)\n",
    "ax = fluvial_joined['FLUV_AAL'].plot(figsize=(32,4))\n",
    "ax.set_ylim(0,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Pluvial AAL Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pluv_s3files = [x for x in s3files if 'P0' in x]\n",
    "for p in pluv_s3files:\n",
    "    if TRI:\n",
    "        model = os.path.basename(p).split('_')[-3]\n",
    "    else:\n",
    "        model = os.path.basename(p).split('_')[-2]\n",
    "    dp = pd.read_csv(p)\n",
    "    dp.rename(columns={'AAL':'{}_AAL'.format(model)}, inplace=True)\n",
    "    dp.set_index('plus_code', inplace=True)\n",
    "    pluvial_joined = pluvial_joined.join(dp, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to see if any row has more than one positive value... if so, defer to the last column that is not zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pluvial_joined = pluvial_joined.fillna(0)\n",
    "## This will set all pluvial AAL columns to 0 except for the last one.\n",
    "pluv_dups = [1]\n",
    "while len(pluv_dups) > 0:\n",
    "    # check for dups, append the plus_code to a list\n",
    "    pluv_dups = []\n",
    "    for row in list(zip(pluvial_joined.index, map(set, pluvial_joined.values))):\n",
    "        if len(row[1]) > 2:\n",
    "            pluv_dups.append(row[0])\n",
    "    print('plus_codes with more than one pluvial AAL:', pluv_dups)\n",
    "    # set the aal = to zero except for the last one\n",
    "    for pcode in pluv_dups:\n",
    "        for i, col in enumerate(pluvial_joined.columns.tolist()):\n",
    "            if pluvial_joined.loc[pcode, col] != 0:  # we are deffering to the last model with a value\n",
    "                pluvial_joined.loc[pcode, col] = 0\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one pluvial aal for each point\n",
    "pluvial_joined['PLUV_AAL'] = pluvial_joined.sum(axis=1)\n",
    "ax = pluvial_joined['PLUV_AAL'].plot(figsize=(32,4))\n",
    "ax.set_ylim(0,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the fluvial and pluvial results to get a final AAL dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_product = pd.DataFrame(pluvial_joined['PLUV_AAL']).join(pd.DataFrame(fluvial_joined['FLUV_AAL']), how='outer')\n",
    "final_product['TOT_AAL'] = final_product.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = final_product['TOT_AAL'].plot(figsize=(32,4))\n",
    "ax.set_ylim(0,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_product.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_product.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the building attributes and ground elevation to the final AAL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a dataframe of only the idxs\n",
    "idx_only = final_product.copy().drop(columns=final_product.columns.tolist())\n",
    "\n",
    "temp_dfs = []\n",
    "for f in s3files:\n",
    "    # read the attribute files\n",
    "    if TRI:\n",
    "        attrs_f = f.replace('Results/TRI', 'Attributes').replace('AAL_', '').replace('_TRI', '')\n",
    "    else:\n",
    "        attrs_f = f.replace('Results', 'Attributes').replace('AAL_', '')\n",
    "    attr_df = pd.read_csv(attrs_f).set_index('plus_code').drop(columns=['geom', 'damage_code'])\n",
    "    \n",
    "    # drop the shp_nam column that is only in some csvs\n",
    "    try:\n",
    "        attr_df = attr_df.drop(columns=['shp_nam'])\n",
    "    except KeyError as e:\n",
    "        print(e, 'for {}'.format(attrs_f))\n",
    "    \n",
    "    # get the ground elevations. These are only available in the WSE files\n",
    "    wse_f = f.replace('AAL', 'WSE')\n",
    "    groundelev = pd.read_csv(wse_f).set_index('plus_code')[['GroundElev']]\n",
    "    \n",
    "    # join the dataframes together and append to a list for concatenation\n",
    "    attr_temp = idx_only.join(attr_df, how='inner')\n",
    "    ge_temp = idx_only.join(groundelev, how='inner')\n",
    "    temp = attr_temp.join(ge_temp)\n",
    "    temp_dfs.append(temp)\n",
    "\n",
    "# concatenate the data into one dataframe, dropping duplicates\n",
    "attr_data = pd.concat(temp_dfs).drop_duplicates()\n",
    "# drop rows that have duplicate indices, keeping the first row\n",
    "# these dups happen when ground elevations are different between models\n",
    "attr_data = attr_data.loc[~attr_data.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the attribute data to the final AAL dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_product = final_product.join(attr_data, how='inner')\n",
    "final_data_product.index.name = 'plus_code'\n",
    "final_data_product['Excluded'] = None # leave this as null for now...\n",
    "if 'pfra_cat' in list(final_data_product.columns):\n",
    "    final_data_product = final_data_product.drop(columns=['pfra_cat'])\n",
    "print('Final shape: {}'.format(final_data_product.shape))\n",
    "final_data_product.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the final table to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the file\n",
    "final_fn = 'Final_AAL_{0}_{1}{2}.csv'.format(project, book, TRI)\n",
    "final_path = os.path.join(output_dir, final_fn)\n",
    "final_data_product.to_csv(final_path)\n",
    "print('Result written: {}'.format(final_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
