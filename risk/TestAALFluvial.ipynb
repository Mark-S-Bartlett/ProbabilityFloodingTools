{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAPERMILL\n",
    "wse_file = 's3://pfra/RiskAssessment/DC/Results/F02/WSE_DC_F02_Uniform.csv'\n",
    "breach_prob_file = 's3://pfra/RiskAssessment/DC/BreachAnalysis/DC_F02_raw_prob_table.csv'\n",
    "weights_file = 's3://pfra/RiskAssessment/DC/BreachAnalysis/DC_F02.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory = C:\\Users\\slawler\\GitRepos\\probmod-tools\\core\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('../core')\n",
    "from risk_refactor import *\n",
    "from importlib import reload\n",
    "print('Working Directory = {}'.format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust curves for current FEMA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultHazusDDFn_path = '../risk/hazusdepthdmgfns/Building_DDF_Full_LUT_Hazus3p0.json'\n",
    "df_BDDFn = pd.read_json(defaultHazusDDFn_path, orient = 'index')\n",
    "df_BDDFn = hazusID_to_depth(df_BDDFn)\n",
    "df_agg = aggregate_ddf_curves(df_BDDFn, curve_groups, plot=False)\n",
    "\n",
    "# set curve for single family 1 story no basement\n",
    "df_agg.loc[-1, 'singFam_1Story_NoBasement']= 0.6\n",
    "df_agg.loc[-0.000000000001, 'singFam_1Story_NoBasement']= 0.6\n",
    "\n",
    "# set curve for single family 2 story no basement\n",
    "df_agg.loc[-1, 'singFam_2Story_NoBasement']= 0.6\n",
    "df_agg.loc[-0.000000000001, 'singFam_2Story_NoBasement']= 0.6\n",
    "\n",
    "# set curve for single family 3 story no basement\n",
    "df_agg.loc[-1, 'singFam_3Story_NoBasement']= 0.0\n",
    "df_agg.loc[-0.000000000001, 'singFam_3Story_NoBasement']= 0.0\n",
    "\n",
    "# set curve for mobile home\n",
    "df_agg.loc[-0.000000000001, 'mobileHome']= 0.75\n",
    "\n",
    "df_agg = df_agg.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_locations = ['87C5W2MX+5G9GF53',\n",
    "                    '87C5W2MX+6G69853',\n",
    "                    '87C5W2MX+6M47X34',\n",
    "                    '87C5W2MX+9JWGM55',\n",
    "                    '87C5W2MX+FRP9M22',\n",
    "                    '87C5W2MX+CP6Q933',\n",
    "                    '87C5W2RV+FQMRF34',\n",
    "                    '87C5W2RW+F7G5222',\n",
    "                    '87C5W2RW+FFH8R33',\n",
    "                    '87C5W2RV+FWGGP35',\n",
    "                    '87C5W2RV+GHC4345',\n",
    "                    '87C5W2RW+G5F9R24',\n",
    "                    '87C5W2RW+GG4R953',\n",
    "                    '87C5W2RV+GQX3R45',\n",
    "                    '87C5W2RV+GW9X234',\n",
    "                    '87C5W2RV+HRJM344',\n",
    "                    '87C5W2RW+GHRP625',\n",
    "                    '87C5W2RW+H3PVR53',\n",
    "                    '87C5W2RV+R9G7534',\n",
    "                    '87C5W2RW+H43P443',\n",
    "                    '87C5W2RW+H85V532',\n",
    "                    '87C5W2RV+MRMJV34',\n",
    "                    '87C5W2RV+MVMXW25',\n",
    "                    '87C5W2RV+RGR9R32',\n",
    "                    '87C5W2RV+MX39F45',\n",
    "                    '87C5W2RW+H9V9525',\n",
    "                    '87C5W2RV+RW47454',\n",
    "                    '87C5W2RW+HHHQ855',\n",
    "                    '87C5W2RV+PG7VG42',\n",
    "                    '87C5W2RV+PHF5Q45',\n",
    "                    '87C5W2RV+VXFH525',\n",
    "                    '87C5W2RV+PJP2M52',\n",
    "                    '87C5W2RW+J29M725',\n",
    "                    '87C5W2RV+WPJ5252',\n",
    "                    '87C5W2RW+J6VH724',\n",
    "                    '87C5W2RW+JCJCH23',\n",
    "                    '87C5W2RV+PMM9C24',\n",
    "                    '87C5W2RV+PPX3C25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfwse = pd.read_csv(wse_file, index_col='plus_code')\n",
    "dfw = pd.read_excel(weights_file, sheet_name='Event_Weights', index_col=0 )[['Overall Weight']]\n",
    "dfbp = pd.read_table(breach_prob_file, index_col=0)\n",
    "for col in dfbp.columns:\n",
    "    dfbp.rename(columns={col:col.split('_')[1]}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in e.event_weights.index:\n",
    "    #print(event)\n",
    "    event_map['NBR_{}'.format(event)] = e.event_weights.loc[event, 'Overall Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 87C5W2MX+5G9GF53 0.8010403554634713\n",
      "1 87C5W2MX+6G69853 1.7931507462507792\n",
      "2 87C5W2MX+6M47X34 37.311378596143896\n",
      "3 87C5W2MX+9JWGM55 14.801945817670743\n",
      "4 87C5W2MX+FRP9M22 0.7856212827536633\n",
      "5 87C5W2MX+CP6Q933 29.82768191685065\n",
      "6 87C5W2RV+FQMRF34 2.1910534185967787\n",
      "7 87C5W2RW+F7G5222 8.037105510328502\n",
      "8 87C5W2RW+FFH8R33 7.909668015372577\n",
      "9 87C5W2RV+FWGGP35 2.9594282715034232\n",
      "10 87C5W2RV+GHC4345 0\n",
      "11 87C5W2RW+G5F9R24 7.6546307566310725\n",
      "12 87C5W2RW+GG4R953 12.982804290771362\n",
      "13 87C5W2RV+GQX3R45 1.5281650756552807\n",
      "14 87C5W2RV+GW9X234 2.881820563323201\n",
      "15 87C5W2RV+HRJM344 0.7638505067742825\n",
      "16 87C5W2RW+GHRP625 14.317262574914439\n",
      "17 87C5W2RW+H3PVR53 4.218165038825275\n",
      "18 87C5W2RV+R9G7534 0\n",
      "19 87C5W2RW+H43P443 6.4589193604528905\n",
      "20 87C5W2RW+H85V532 9.853341932027753\n",
      "21 87C5W2RV+MRMJV34 2.2872961965336076\n",
      "22 87C5W2RV+MVMXW25 2.8083129825410835\n",
      "23 87C5W2RV+RGR9R32 1.3542232166031103\n",
      "24 87C5W2RV+MX39F45 4.822444015648348\n",
      "25 87C5W2RW+H9V9525 9.716112225521101\n",
      "26 87C5W2RV+RW47454 3.0459214427302395\n",
      "27 87C5W2RW+HHHQ855 14.93918011602322\n",
      "28 87C5W2RV+PG7VG42 0\n",
      "29 87C5W2RV+PHF5Q45 0.35377648267883444\n"
     ]
    }
   ],
   "source": [
    "for i, pcode in enumerate(test_locations[0:30]):\n",
    "    # Initialize loss a point to zero\n",
    "    aal = 0\n",
    "    #dfwse = the row of results from dfwse\n",
    "    event_data = dfwse.loc[pcode]\n",
    "    \n",
    "    p = FluvialPoint(pcode, event_data)\n",
    "    \n",
    "    e = FluvialEvents(dfw, dfbp)\n",
    "    \n",
    "    breaches  = p.breach_influence\n",
    "    weights_map[p.plus_code] = {}\n",
    "    \n",
    "    if len(breaches) >0:\n",
    "        breach_prob = {}\n",
    "        for b in e.breach_locations:\n",
    "            breach_prob[b]= e.breach_probs(b).to_dict()\n",
    "\n",
    "        event_map = {}\n",
    "        \n",
    "        for idx, b in enumerate(breaches):\n",
    "            for event in e.event_weights.index:\n",
    "                event_map['{}'.format(b)] = breach_prob[b][event]\n",
    "                test_breach_probs = calculate_breach_weights(event, event_map)\n",
    "\n",
    "                test_breach_weights = {}\n",
    "                for br_ev, prob in test_breach_probs.items():\n",
    "                    ev = br_ev.split('_')[1]\n",
    "                    wt = prob * e.event_weights.loc[ev, 'Overall Weight']\n",
    "                    test_breach_weights[br_ev] = wt \n",
    "\n",
    "                for k, v in test_breach_weights.items():\n",
    "                    weights_map[p.plus_code][k] = v\n",
    "    else:\n",
    "        for event in e.event_weights.index:\n",
    "            weights_map[p.plus_code]['NBR_{}'.format(event)] = e.event_weights.loc[event, 'Overall Weight']\n",
    "                \n",
    "    bld_lmt = p.attributes['limitbuilding']\n",
    "    bld_ded = p.attributes['deductiblebuilding']\n",
    "    dmg_code = p.attributes['damage_code']\n",
    "    ffh = p.attributes['firstfloorheight']\n",
    "\n",
    "    loss_func = interp1d(df_agg.index, df_agg[dmg_code])\n",
    "\n",
    "    depth_in_building = p.raw_wses - (p.elevation + p.attributes.firstfloorheight)\n",
    "\n",
    "    relevent_events = [e for b in p.breach_influence for e in p.events if b in e]\n",
    "\n",
    "    # Add nbr events\n",
    "    for event in p.nbr_events:\n",
    "        relevent_events.append(event)\n",
    "\n",
    "    for event in relevent_events:\n",
    "        event_depth_in_building = depth_in_building[event]\n",
    "\n",
    "        if event_depth_in_building > df_agg.index.min():\n",
    "\n",
    "            if event_depth_in_building > df_agg.index.max():\n",
    "                event_depth_in_building = highest_ddf_elev\n",
    "\n",
    "            percent_loss = loss_func(event_depth_in_building)/100\n",
    "            loss_val = bld_lmt * percent_loss - bld_ded\n",
    "\n",
    "            if loss_val > 0:\n",
    "                try:\n",
    "                    aal += loss_val * weights_map[p.plus_code][event]\n",
    "                except KeyError as error:\n",
    "                    print('Key Errror', error)\n",
    "                    break\n",
    "\n",
    "    print(i, pcode, aal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
