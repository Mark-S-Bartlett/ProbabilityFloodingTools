{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep AWS Runs\n",
    "\n",
    " 1. Read input zipfile for PFRA model from s3\n",
    " - Perform Scale Tests\n",
    " - Write input zipfiles for:\n",
    "     - Scale Test events\n",
    "     - Production Run events\n",
    "     - Custom events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;sys.path.append('../core')\n",
    "from ras_ops import *\n",
    "from scale_tests import *\n",
    "from time import time, strftime\n",
    "import pytz\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://pfra/Sacramento/BaseModels/Sacramento_P03_H00.zip\n",
      "s3://pfra/Sacramento/Data/Forcing/Pluvial/Outputs/Sacramento_P03_Forcing.zip\n"
     ]
    }
   ],
   "source": [
    "#Make File Paths\n",
    "project_name = \"Sacramento\"\n",
    "model_subtype = \"H00\"\n",
    "model_name = \"P03\"\n",
    "\n",
    "if \"P\" in model_name:\n",
    "    model_type = \"Pluvial\"\n",
    "else:\n",
    "    model_type = \"Fluvial\"\n",
    "    \n",
    "model_s3path = \"s3://pfra/{0}/BaseModels/{0}_{1}_{2}.zip\".format(project_name, model_name, model_subtype)\n",
    "forcing_s3path = \"s3://pfra/{0}/Data/Forcing/{1}/Outputs/{0}_{2}_Forcing.zip\".format(project_name, model_type, model_name)\n",
    "\n",
    "print(model_s3path)\n",
    "print(forcing_s3path)\n",
    "\n",
    "custom_events_csv = r'C:\\Users\\Administrator\\Desktop\\event.csv'\n",
    "df = pd.read_csv(custom_events_csv, header=None)\n",
    "custom_events = df[0].values\n",
    "\n",
    "events = 'CustomEvents'\n",
    "#events = 'ScaleTest'\n",
    "#events = 'ProductionRuns'\n",
    "\n",
    "# Initialize list to store errors\n",
    "errors=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RasModel(model_s3path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Required Files are present, and no 'development' files included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Backup.g01',\n",
       " 'ManningsN/Manning_nValues.hdf',\n",
       " 'ManningsN/Manning_nValues.tif',\n",
       " 'ManningsN/Thumbs.db',\n",
       " 'ProjectionFile.prj',\n",
       " 'Sacramento_P03_H00.b01',\n",
       " 'Sacramento_P03_H00.bco01',\n",
       " 'Sacramento_P03_H00.c02',\n",
       " 'Sacramento_P03_H00.color_scales',\n",
       " 'Sacramento_P03_H00.dss',\n",
       " 'Sacramento_P03_H00.g02',\n",
       " 'Sacramento_P03_H00.g02.hdf',\n",
       " 'Sacramento_P03_H00.IC.O01',\n",
       " 'Sacramento_P03_H00.p01',\n",
       " 'Sacramento_P03_H00.p01.blf',\n",
       " 'Sacramento_P03_H00.p01.hdf',\n",
       " 'Sacramento_P03_H00.prj',\n",
       " 'Sacramento_P03_H00.rasmap',\n",
       " 'Sacramento_P03_H00.rasmap.backup',\n",
       " 'Sacramento_P03_H00.u01',\n",
       " 'Sacramento_P03_H00.x02',\n",
       " 'Terrain/ModelTerrain.hdf',\n",
       " 'Terrain/ModelTerrain.MergedInputs.tif',\n",
       " 'Terrain/ModelTerrain.vrt',\n",
       " 'Terrain/Thumbs.db']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prjData = RasProject(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "planData = RasPlan(model, prjData.current_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "localPlan = HDFPlanFile(model, planData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sacramento_P03_H00.b01', 'Sacramento_P03_H00.x02', 'Sacramento_P03_H00.c02']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localPlan.mandatoryFiles\n",
    "#pl.Path(planData.plan_path).suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://pfra/Sacramento/Data/Forcing/Pluvial/Outputs/Sacramento_P03_Forcing.zip'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forcing_s3path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_data = RASForcing(forcing_s3path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forcing_data.domainForcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform Test Suite \n",
    "\n",
    "*Error class not invoked yet.*\n",
    "\n",
    "This will need to be updated. For now any errors from scale tests are written to a list, but will not impede moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Geometry': ['Backup.g01', 'Sacramento_P03_H00.g02'],\n",
       "  'cFile': ['Sacramento_P03_H00.c02', 'Sacramento_P03_H00.color_scales']}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaleTest = ModelCheck(model)\n",
    "errors = scaleTest.runTests(model, prjData, planData, localPlan, forcing_data)\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep Event list if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0001\n"
     ]
    }
   ],
   "source": [
    "jobsList=[]\n",
    "\n",
    "if events == 'ProductionRuns': \n",
    "    events = forcing_data.productionEvents\n",
    "    \n",
    "elif events == 'ScaleTest':\n",
    "    events = scaleTestEvents(model_s3path)\n",
    "    \n",
    "else:\n",
    "    events = custom_events.tolist()\n",
    "    \n",
    "for e in events: print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare BC's in Forcing with BC's in Model\n",
    "\n",
    "*If the names are not consistent the Main Function will not create input files. Please verify all BC's that should be included are in the __Forcing__ File and in the __Model__ File*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BC's found in Forcing File:\n",
      "\tDomain: D36: ['D36']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: D37: ['D37', 'L18', 'L19', 'L20', 'L21', 'L22', 'L23', 'L24', 'L25', 'L26', 'L27', 'L29', 'L31', 'L32', 'L33', 'L40', 'L41', 'L42', 'L43', 'L44', 'L87']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: D38: ['D38', 'L13', 'L14', 'L17']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: D39: ['D39']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: D40: ['D40']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: D41: ['D41', 'L07', 'L08', 'L28', 'L30', 'L34', 'L35', 'L36', 'L37', 'L38', 'L39']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: D42: ['D42']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: RiverD37: ['F02']\n",
      "BC's found in Forcing File:\n",
      "\tDomain: RiverD38: ['F01']\n",
      "\n",
      "BC's found in Model File:\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L18\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L19\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L20\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L21\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L22\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L23\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L24\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L25\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L26\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L27\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L29\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L31\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L32\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L33\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L40\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L41\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L42\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L43\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L44\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D37 BCLine: L87\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D38 BCLine: L13\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D38 BCLine: L14\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D38 BCLine: L17\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L07\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L08\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L28\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L30\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L34\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L35\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L36\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L37\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L38\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: D41 BCLine: L39\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: RiverD37 BCLine: F02\n",
      "Event Conditions/Unsteady/Boundary Conditions/Flow Hydrographs/SA: RiverD38 BCLine: F01\n",
      "Event Conditions/Unsteady/Boundary Conditions/Normal Depths/SA: D40 BCLine: N01\n",
      "Event Conditions/Unsteady/Boundary Conditions/Normal Depths/SA: D42 BCLine: N02\n",
      "Event Conditions/Unsteady/Boundary Conditions/Normal Depths/SA: RiverD42 BCLine: N03\n",
      "Event Conditions/Unsteady/Boundary Conditions/Precipitation Hydrographs/SA: D36\n",
      "Event Conditions/Unsteady/Boundary Conditions/Precipitation Hydrographs/SA: D37\n",
      "Event Conditions/Unsteady/Boundary Conditions/Precipitation Hydrographs/SA: D38\n",
      "Event Conditions/Unsteady/Boundary Conditions/Precipitation Hydrographs/SA: D39\n",
      "Event Conditions/Unsteady/Boundary Conditions/Precipitation Hydrographs/SA: D40\n",
      "Event Conditions/Unsteady/Boundary Conditions/Precipitation Hydrographs/SA: D41\n",
      "Event Conditions/Unsteady/Boundary Conditions/Precipitation Hydrographs/SA: D42\n"
     ]
    }
   ],
   "source": [
    "domains_in_forcing = list(forcing_data.domainForcing.keys())\n",
    "for d in domains_in_forcing:\n",
    "    bcs = forcing_data.domainForcing[d]\n",
    "    event_types = bcs.keys()\n",
    "    for event_type in event_types:\n",
    "        bc_names = bcs[event_type]['BCName'].keys()\n",
    "    \n",
    "    print(\"BC's found in Forcing File:\\n\\tDomain: {}: {}\".format( d, list(bc_names)))\n",
    "    \n",
    "print(\"\\nBC's found in Model File:\")\n",
    "for bc in localPlan.planHydrograpList:\n",
    "    #continue\n",
    "    print(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Main Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0001\n",
      "!---\tVerify RiverD42 does not have BC's that need to be overwritten, no data found in forcing json\n",
      "s3://pfra/Sacramento/P03/H06/E0001/Sacramento_P03_H06_E0001_in.zip Completed in 3.7154548168182373 seconds\n"
     ]
    }
   ],
   "source": [
    "localPlan = HDFPlanFile(model, planData)\n",
    "# Loop over events\n",
    "for event in events:\n",
    "    print(event)\n",
    "    start=time()\n",
    "    # Loop over domains in the model\n",
    "    for domain in localPlan.domains:\n",
    "        \n",
    "        try:\n",
    "            # There may be domains that have no boundaries requiring forcing updates\n",
    "            updateRasData = GetModelEventData(event, forcing_data)\n",
    "            \n",
    "            # Verify Data exists in at least one domain for the event\n",
    "            forcing_vectors = 0\n",
    "            \n",
    "            for k, v in updateRasData.items(): \n",
    "                forcing_vectors += len(v)\n",
    "                \n",
    "            assert forcing_vectors > 0, \"No Forcing for this event found, please verify event exists\"\n",
    "            \n",
    "        except KeyError as e:\n",
    "            print(\"!---\\tVerify {} does not have BC's that need to be overwritten, no data found in forcing json\".format(domain))\n",
    "\n",
    "\n",
    "        # Loop over all boundary conditions per domain\n",
    "        try:\n",
    "            forcing_data_boundary_names = updateRasData[domain].keys()\n",
    "        \n",
    "            for bc in forcing_data_boundary_names:\n",
    "\n",
    "                # modelDescriptor is first key in forcing: Fluvial, H06, etc.\n",
    "                modelDescriptor = updateRasData[domain][bc]['modelDescriptor']\n",
    "                tseries = updateRasData[domain][bc]['tseries']\n",
    "\n",
    "                # Get full path in hdf to update\n",
    "                bcLocalPath = bc_hdf_path(model, domain, bc, localPlan.planHydrograpList)\n",
    "                #print('Processing {}'.format(bcLocalPath))\n",
    "\n",
    "                # update plan file with event data\n",
    "                localPlan.updateHydrograph(bcLocalPath, tseries)\n",
    "\n",
    "                # Update start, end date for time series\n",
    "                Start_Date = updateRasData[domain][bc]['start_date']\n",
    "                End_Date = updateRasData[domain][bc]['end_date']\n",
    "\n",
    "                # Update model runtime for all boundary conditions\n",
    "                localPlan.updateSimDates(event, Start_Date, End_Date)\n",
    "                #localPlan.cellCount\n",
    "        except KeyError as e:\n",
    "            print(\"!---\\tVerify {} does not have BC's that need to be overwritten, no data found in forcing json\".format(domain))\n",
    "\n",
    "\n",
    "\n",
    "    rawModelFiles =  prepEventZipFiles(event, model, localPlan, prjData, modelDescriptor)\n",
    "    \n",
    "    updateComputeFiles(model, rawModelFiles, event, Start_Date, End_Date)\n",
    "    \n",
    "    runName = pushModeltoS3(rawModelFiles)\n",
    "    \n",
    "    jobsList.append(runName)\n",
    "    \n",
    "    # grab cell count for SOM\n",
    "    cellCount = np.ones(len(jobsList))*localPlan.cellCount\n",
    "    print('{} Completed in {} seconds'.format(runName, time() - start))\n",
    "    \n",
    "tmpFile = localPlan.hdfLocal.filename\n",
    "localPlan.hdfLocal.close()\n",
    "del localPlan; os.remove(tmpFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create job file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobs</th>\n",
       "      <th>cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s3://pfra/Sacramento/P03/H06/E0001/Sacramento_...</td>\n",
       "      <td>225404.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                jobs     cells\n",
       "0  s3://pfra/Sacramento/P03/H06/E0001/Sacramento_...  225404.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create df with cell count, jobs\n",
    "s3JobsDF = pd.DataFrame(data = {'jobs':jobsList, 'cells':cellCount} )\n",
    "\n",
    "# add timestamp to filename\n",
    "#sendTime = datetime.datetime.now( pytz.timezone(\"UTC\") ).strftime(\"%Y-%m-%d %I:%M:%S %Z\")\n",
    "sendTime = datetime.datetime.now( pytz.timezone(\"UTC\") ).strftime(\"%Y%m%d_%I%M%S_%Z\")\n",
    "\n",
    "# make path to save csv on s3\n",
    "s3RunFile = model.s3path.replace('BaseModels','Jobs').replace('.zip','_{}.csv'.format(sendTime))\n",
    "s3JobsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write job file to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to s3://pfra/Sacramento/Jobs/Sacramento_P03_H00_20191003_043141_UTC.csv\n"
     ]
    }
   ],
   "source": [
    "csv_buffer = StringIO()\n",
    "s3JobsDF.to_csv(csv_buffer, sep=\",\", index=False)\n",
    "sendJobs= s3.Object('pfra', s3RunFile.replace('s3://pfra/','')).put(Body=csv_buffer.getvalue())\n",
    "print('File written to {}'.format(s3RunFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
